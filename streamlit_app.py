#from file: streamlit_app_chatgpt_ai_app_csv_v1_2.py
# -----------------------------------------------------------------------------
import pandas as pd
import numpy as np
import streamlit as st
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import plotly.express as px
import requests
import io
from sklearn.preprocessing import LabelEncoder

# ============================
# Step 1: Load and preprocess data
# ============================

def load_data():
    source = st.sidebar.radio("Ch·ªçn ngu·ªìn d·ªØ li·ªáu:", ["CSV URL", "Upload CSV", "API"], index=0)

    if source == "CSV URL":
        # URL ch·ª©a d·ªØ li·ªáu ch·ª©ng kho√°n m·∫´u
        # sample_history_stockData.csv
        # csv_url = "https://gist.githubusercontent.com/thaonbtfin/fcb2906734735389faa0d32c8b47d456/raw/5dcc232d24f45b95e388e334c3ceeddc874752e9/sample_history_stockData.csv"
        # TH_toGoogleSheet.csv
        csv_url="https://gist.githubusercontent.com/thaonbtfin/702773bb825afd63553f515b61645e8b/raw/8fe2a6cfe9cb5db792eabf07bf0d61d7f525b5c0/TH_toGoogleSheet.csv"
        # # TH_toGoogleSheet.csv
        # csv_url="https://gist.githubusercontent.com/thaonbtfin/4c3a7018a1058d5f1e31fcf91d2367a9/raw/6205af6e9522710c4e88c80cbe234c1592fa5d05/DH_toGoogleSheet.csv"
        try:
            # url = "https://gist.githubusercontent.com/thaonbtfin/fcb2906734735389faa0d32c8b47d456/raw/5dcc232d24f45b95e388e334c3ceeddc874752e9/sample_history_stockData.csv"
            url = csv_url
            st.info(f"ƒêang t·∫£i d·ªØ li·ªáu t·ª´: {url}")
            response = requests.get(url)
            df = pd.read_csv(io.StringIO(response.text))
        except Exception as e:
            st.error(f"Kh√¥ng th·ªÉ t·∫£i file CSV: {e}")
            return pd.DataFrame()

    elif source == "Upload CSV":
        uploaded_file = st.sidebar.file_uploader("Upload file CSV ch·ª©a d·ªØ li·ªáu ch·ª©ng kho√°n", type=["csv"])
        if uploaded_file is not None:
            try:
                df = pd.read_csv(uploaded_file)
            except Exception as e:
                st.error(f"L·ªói ƒë·ªçc file CSV: {e}")
                return pd.DataFrame()
        else:
            return pd.DataFrame()

    elif source == "API":
        try:
            api_url = "https://api.mocki.io/v2/12345678/stockdata"  # Replace with actual API URL
            response = requests.get(api_url)
            json_data = response.json()
            df = pd.DataFrame(json_data)
        except Exception as e:
            st.error(f"Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu t·ª´ API: {e}")
            return pd.DataFrame()

    df['time'] = pd.to_datetime(df['time'], format='%Y%m%d')
    df.sort_values('time', inplace=True)
    return df

def calculate_technical_indicators(data):
    data['ma5'] = data['close'].rolling(window=5).mean()
    data['ma10'] = data['close'].rolling(window=10).mean()
    data['return_1d'] = data['close'].pct_change(1)
    data['return_5d'] = data['close'].pct_change(5)
    delta = data['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    data['rsi'] = 100 - (100 / (1 + rs))
    return data

def add_financial_indicators(data):
    np.random.seed(42)
    data['eps'] = np.random.normal(5, 0.5, size=len(data))
    data['roe'] = np.random.normal(15, 2, size=len(data))
    return data

def create_features(df, stock):
    data = df[['time', stock]].copy()
    data.rename(columns={stock: 'close'}, inplace=True)
    data = calculate_technical_indicators(data)
    data = add_financial_indicators(data)
    future_return = data['close'].shift(-5) / data['close'] - 1
    data['action'] = pd.cut(
        future_return,
        bins=[-np.inf, -0.05, 0.05, np.inf],
        labels=['Sell', 'Hold', 'Buy']
    )
    data.dropna(inplace=True)
    return data

def train_model(data):
    X = data[['ma5', 'ma10', 'return_1d', 'return_5d', 'rsi', 'eps', 'roe']]
    y = data['action']

    if y.nunique() < 2:
        raise ValueError("C·∫ßn √≠t nh·∫•t 2 l·ªõp (Buy/Hold/Sell) ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh")

    le = LabelEncoder()
    y_encoded = le.fit_transform(y)

    class_counts = pd.Series(y_encoded).value_counts()
    min_class_count = class_counts.min()

    if min_class_count < 2:
        st.warning("M·ªôt s·ªë l·ªõp qu√° √≠t d·ªØ li·ªáu ƒë·ªÉ ph√¢n chia train/test. S·∫Ω hu·∫•n luy·ªán to√†n b·ªô d·ªØ li·ªáu.")
        X_train, y_train = X, y_encoded
        X_test, y_test = X, y_encoded
    else:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
        )

    model = XGBClassifier(
        n_estimators=300,
        learning_rate=0.05,
        max_depth=5,
        subsample=0.8,
        colsample_bytree=0.8,
        use_label_encoder=False,
        eval_metric='mlogloss',
        random_state=42
    )
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    report = classification_report(y_test, y_pred, target_names=le.classes_, output_dict=True)
    return model, report, le

# Backtest logic and UI tab integration
def run_backtest(data):
    capital = 1.0
    position = 0
    capital_history = []

    for i in range(len(data)):
        action = data.iloc[i]['predicted_action']
        price = data.iloc[i]['close']

        if action == 'Buy' and position == 0:
            position = capital / price
            capital = 0
        elif action == 'Sell' and position > 0:
            capital = position * price
            position = 0

        current_value = capital if position == 0 else position * price
        capital_history.append(current_value)

    data['portfolio_value'] = capital_history
    return data

# ============================
# Streamlit UI
# ============================
st.set_page_config(page_title="AI D·ª± ƒëo√°n Ch·ª©ng kho√°n", layout="wide")
st.title("üìä AI khuy·∫øn ngh·ªã Mua / Gi·ªØ / B√°n c·ªï phi·∫øu")

with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu v√† hu·∫•n luy·ªán m√¥ h√¨nh..."):
    df = load_data()
    if df.empty:
        st.warning("Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã.")
        st.stop()

    tickers = [col for col in df.columns if col not in ['time', 'VNINDEX']]
    models = {}
    latest_predictions = []

    for ticker in tickers:
        data = create_features(df, ticker)
        if data['action'].nunique() < 2:
            continue
        try:
            model, report, le = train_model(data)
        except Exception as e:
            st.warning(f"L·ªói khi hu·∫•n luy·ªán m√¥ h√¨nh cho {ticker}: {e}")
            continue

        models[ticker] = (model, data, report, le)
        latest = data.iloc[-1]

        pred_encoded = model.predict([latest[['ma5', 'ma10', 'return_1d', 'return_5d', 'rsi', 'eps', 'roe']].values])[0]
        pred_label = le.inverse_transform([pred_encoded])[0]

        accuracy = report.get('accuracy', 0) * 100

        latest_predictions.append({
            'M√£': ticker,
            'Gi√° hi·ªán t·∫°i': latest['close'],
            'Khuy·∫øn ngh·ªã': pred_label,
            'Accuracy (%)': f"{accuracy:.2f}%"
        })

    latest_predictions_df = pd.DataFrame(latest_predictions)
    latest_predictions_df['Ng√†y cu·ªëi'] = latest_predictions_df['M√£'].apply(lambda t: models[t][1]['time'].max())
    latest_predictions_df = latest_predictions_df.sort_values(by='Ng√†y cu·ªëi', ascending=False).drop(columns=['Ng√†y cu·ªëi'])

all_tab, detail_tab, backtest_tab, report_tab = st.tabs(["üìã T·∫•t c·∫£ c·ªï phi·∫øu", "üîç Chi ti·∫øt c·ªï phi·∫øu", "üß™ Gi·∫£ l·∫≠p hi·ªáu su·∫•t chi·∫øn l∆∞·ª£c", "üìà Hi·ªáu nƒÉng m√¥ h√¨nh"])

with all_tab:
    st.subheader("Khuy·∫øn ngh·ªã t·ªïng h·ª£p")
    st.dataframe(latest_predictions_df)

with detail_tab:
    selected = st.selectbox("Ch·ªçn m√£ c·ªï phi·∫øu", list(models.keys()))
    model, data, report, le = models[selected]
    last_rows = data.tail(100).copy()

    pred_encoded = model.predict(last_rows[['ma5', 'ma10', 'return_1d', 'return_5d', 'rsi', 'eps', 'roe']])
    last_rows['predicted_action'] = le.inverse_transform(pred_encoded)

    accuracy = report.get('accuracy', 0) * 100
    last_rows['Accuracy (%)'] = f"{accuracy:.2f}%"

    last_rows = last_rows.sort_values(by='time', ascending=False)

    st.subheader(f"Bi·ªÉu ƒë·ªì gi√° v√† khuy·∫øn ngh·ªã: {selected}")
    fig = px.line(last_rows, x='time', y='close', title=f'Gi√° ƒë√≥ng c·ª≠a - {selected}')
    st.plotly_chart(fig, use_container_width=True)

    st.dataframe(last_rows[['time', 'close', 'ma5', 'rsi', 'eps', 'roe', 'predicted_action', 'Accuracy (%)']].reset_index(drop=True))

with backtest_tab:
    st.subheader("Gi·∫£ l·∫≠p hi·ªáu su·∫•t chi·∫øn l∆∞·ª£c")
    selected_bt = st.selectbox("Ch·ªçn m√£ c·ªï phi·∫øu ƒë·ªÉ backtest", list(models.keys()), key="backtest_select")

    model, data_bt, _, le = models[selected_bt]
    last_rows_bt = data_bt.tail(200).copy()
    pred_encoded_bt = model.predict(last_rows_bt[['ma5', 'ma10', 'return_1d', 'return_5d', 'rsi', 'eps', 'roe']])
    last_rows_bt['predicted_action'] = le.inverse_transform(pred_encoded_bt)

    bt_result = run_backtest(last_rows_bt)

    fig_bt = px.line(bt_result, x='time', y='portfolio_value', title=f'Gi√° tr·ªã danh m·ª•c n·∫øu l√†m theo khuy·∫øn ngh·ªã - {selected_bt}')
    st.plotly_chart(fig_bt, use_container_width=True)
    st.write(f"Gi√° tr·ªã cu·ªëi c√πng: {bt_result['portfolio_value'].iloc[-1]:.2f}x so v·ªõi v·ªën ban ƒë·∫ßu")

with report_tab:
    st.subheader("B√°o c√°o ƒë·ªô ch√≠nh x√°c m√¥ h√¨nh")
    for ticker in models:
        _, _, report, _ = models[ticker]
        st.markdown(f"### {ticker}")
        st.json(report)