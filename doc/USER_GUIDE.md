# ğŸ“ˆ TAstock User Guide

## ğŸš€ Quick Start

### VIEW STREAMLIT SITE
```bash
streamlit run streamlit_app_tastock.py
```
- Data will be automatically loaded from the latest `data/YYYYMMDD/` folder
- Portfolio symbols are read directly from CSV file headers
- No external API calls needed during dashboard usage

## ğŸ”„ Update Data

You have **3 options** to update data:

### Option 1: Complete Data Update (In Streamlit)
- Click **ğŸ“Š Complete Data Update** button in Streamlit sidebar
- Runs full data pipeline automatically (takes ~5 minutes)
- Page refreshes automatically when complete
- **Most convenient option**

### Option 2: Complete Data Pipeline (Command Line)
```bash
python src/tastock/workflows/wf_stock_data_updater.py
```
- Same as Option 1 but run manually
- **Then**: Refresh browser to see updated data

### Option 3: Refresh Portfolios Only
- Click **ğŸ”„ Refresh Portfolios** button in Streamlit sidebar
- Only refreshes portfolio symbol lists (if composition changed)
- Does **not** update stock prices or analysis data

## ğŸ“ Data Structure

After running the workflow, data is organized as:
```
data/
â”œâ”€â”€ 20251118/                    # Latest date folder
â”‚   â”œâ”€â”€ VN30/
â”‚   â”‚   â””â”€â”€ history_data_all_symbols.csv    # VN30 stock data
â”‚   â”œâ”€â”€ VN100/
â”‚   â”‚   â””â”€â”€ history_data_all_symbols.csv    # VN100 stock data
â”‚   â”œâ”€â”€ LongTerm/
â”‚   â”‚   â””â”€â”€ history_data_all_symbols.csv    # User portfolio data
â”‚   â””â”€â”€ BizUni/
â”‚       â””â”€â”€ history_data_all_symbols.csv    # BizUni portfolio data
â”œâ”€â”€ investment_signals_complete.csv         # Investment analysis
â””â”€â”€ bizuni_cpgt.csv                         # BizUni intrinsic values
```

## ğŸ¯ Portfolio Sources

- **VN30/VN100**: From TradingView (market indices)
- **LongTerm/MidTerm**: From Google Sheets (user portfolios)  
- **BizUni**: From bizuni_crawler (value analysis)

## âš¡ Performance

- **Portfolio loading**: 0.01s (reads from CSV headers)
- **Dashboard startup**: ~1s (all data from local CSV files)
- **No external dependencies**: Works offline after data pipeline runs